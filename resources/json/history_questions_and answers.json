[
    {
        "question":  "Tell us about your experience designing and implementing data solutions. Can you give examples of your past projects?",
        "answer":  "In my 20 years of experience, I have worked on a variety of projects involved in designing, testing, and maintaining of robust data pipelines. For instance, in my role at Walmart, I led a team that created a sophisticated software solution to analyze vendor contracts, which saved the company $325M annually. I have also created projects like the Amazon Vine Analysis utilizing AWS, Spark, Python. In most recent months, I have create several data pipelines utilizing APIs, PostgreSQL, SQLite, SQL, Python (and several of its libraries), JavaScript, HTML5. "
    },
    {
        "question":  "How have you utilized cloud technologies like AWS or Azure in your past work?",
        "answer":  "in my Amazon Vine Analysis project, I used AWS RDS for relational data storage and AWS S3 for scalable storage of large datasets."
    },
    {
        "question":  "Can you describe a situation where you had to optimize a data pipeline?",
        "answer":  "At Black Hills Energy, I led a project to create an optimized data pipeline for positively identifying customer sales being recorded on by a third party's system as well as our own. I had to correct the pipeline's processing order and then create complex SQL queries to positively identify sales and send commissions at the correct time. "
    },
    {
        "question":  "Can you describe a situation where you had to optimize database performance?",
        "answer":  "The most recent thing I optimize was my own script for filtering stock data. I originally wrote it so that it was easy to understand. However, after looking at its metrics, I found a method of optimizing the processing. I have a good gut for knowing how things should perform. "
    },
    {
        "question":  "What experience do you have with ETL tools, specifically Informatica?",
        "answer":  "I haven't had any previous experience with Informatica; however, the experience I have had with other scheduling and ETL tools leads me to believe learning in"
    },
    {
        "question":  "How do you approach collaboration with cross-functional teams in a data engineering project?",
        "answer":  "Throughout my career, I have always valued strong collaboration with cross-functional teams. At Walmart, I worked closely with product managers, data scientists, and other stakeholders to deliver real-time financial solutions. I actively participated in Agile methodologies, where we used Scrum and Kanban for iterative development. My experience teaching secondary mathematics also strengthened my ability to break down complex technical concepts into digestible information for non-technical team members."
    },
    {
        "question":  "How do you ensure the security and performance of data systems you've developed?",
        "answer":  "Security is always a top priority for me. At Infosys, I developed encryption software for PCI data to ensure compliance with security standards. I also follow industry best practices to secure sensitive data while maintaining high system performance. For performance, I focus on optimizing data pipelines and tuning queries to ensure scalability and reliability, especially when working with large datasets in cloud environments like AWS."
    },
    {
        "question":  "Why are you interested in working at InSearch-IT and what excites you about this position?",
        "answer":  "I’m excited about the opportunity to work at InSearch-IT because I have a strong passion for data and data engineering, and the technologies you’re using, like Snowflake, AWS, and DBT, align perfectly with my skill set."
    }
    
]